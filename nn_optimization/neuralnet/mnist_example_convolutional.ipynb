{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Optimal adversaries for convolutional MNIST model\n",
    "\n",
    "This notebook gives an example where OMLT is used to find adversarial examples for a trained convolutional neural network. We follow the below steps:<br>\n",
    "1.) A convolutional neural network (CNN) with ReLU activation functions is trained to classify images from the MNIST dataset <br>\n",
    "2.) OMLT is used to generate a mixed-integer encoding of the trained CNN using the big-M formulation <br>\n",
    "3.) The model is optimized to find the maximum classification error (defined by an \"adversarial\" label) over a small input region <br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library Setup\n",
    "This notebook assumes you have a working PyTorch environment to train the neural network for classification. The neural network is then formulated in Pyomo using OMLT which therefore requires working Pyomo and OMLT installations.\n",
    "\n",
    "The required Python libraries used this notebook are as follows: <br>\n",
    "- `numpy`: used for manipulate input data <br>\n",
    "- `torch`: the machine learning language we use to train our neural network\n",
    "- `torchvision`: a package containing the MNIST dataset\n",
    "- `pyomo`: the algebraic modeling language for Python, it is used to define the optimization model passed to the solver\n",
    "- `omlt`: the package this notebook demonstates. OMLT can formulate machine learning models (such as neural networks) within Pyomo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import requisite packages\n",
    "#data manipulation\n",
    "import numpy as np\n",
    "import tempfile\n",
    "\n",
    "#pytorch for training neural network\n",
    "import torch, torch.onnx\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "#pyomo for optimization\n",
    "import pyomo.environ as pyo\n",
    "\n",
    "#omlt for interfacing our neural network with pyomo\n",
    "from omlt import OmltBlock\n",
    "from omlt.neuralnet import FullSpaceNNFormulation\n",
    "from omlt.io.onnx import write_onnx_model_with_bounds, load_onnx_neural_network_with_bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Data and Train a Neural Network\n",
    "\n",
    "We begin by loading the MNIST dataset as `DataLoader` objects with pre-set training and testing batch sizes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set training and test batch sizes\n",
    "train_kwargs = {'batch_size': 64}\n",
    "test_kwargs = {'batch_size': 1000}\n",
    "\n",
    "#build DataLoaders for training and test sets\n",
    "dataset1 = datasets.MNIST('../data', train=True, download=True, transform=transforms.ToTensor())\n",
    "dataset2 = datasets.MNIST('../data', train=False, transform=transforms.ToTensor())\n",
    "train_loader = torch.utils.data.DataLoader(dataset1,**train_kwargs, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define the structure of the convolutional neural network model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 50\n",
    "\n",
    "class Net(nn.Module):\n",
    "    #define layers of neural network\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1  = nn.Conv2d(1, 4, (4,4), (2,2), 0)\n",
    "        self.conv2  = nn.Conv2d(4, 4, (4,4), (2,2), 0)\n",
    "        self.hidden1 = nn.Linear(5*5*4, hidden_size)\n",
    "        self.output  = nn.Linear(hidden_size, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    #define forward pass of neural network\n",
    "    def forward(self, x):\n",
    "        self.x1 = self.conv1(x)\n",
    "        self.x2 = self.relu(self.x1)\n",
    "        self.x3 = self.conv2(self.x2)\n",
    "        self.x4 = self.relu(self.x3)\n",
    "        self.x5 = self.hidden1(self.x4.view((-1,5*5*4)))\n",
    "        self.x6 = self.relu(self.x5)\n",
    "        self.x7 = self.output(self.x6)\n",
    "        x = self.softmax(self.x7)      \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next define simple functions for training and testing the neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training function computes loss and its gradient on batch, and prints status after every 200 batches\n",
    "def train(model, train_loader, optimizer, epoch):\n",
    "    model.train(); criterion = nn.NLLLoss()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 200  == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "#testing function computes loss and prints overall model accuracy on test set\n",
    "def test(model, test_loader):\n",
    "    model.eval(); criterion = nn.NLLLoss(reduction='sum')\n",
    "    test_loss = 0; correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item()  \n",
    "            pred = output.argmax(dim=1, keepdim=True) \n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset)))            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we train the neural network on the dataset.\n",
    "Training here is performed using the `Adadelta` optimizer for five epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.297272\n",
      "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 0.326006\n",
      "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 0.223307\n",
      "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.130190\n",
      "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.115903\n",
      "\n",
      "Test set: Average loss: 0.1250, Accuracy: 9613/10000 (96%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.147509\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.168495\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.144703\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.041711\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.053504\n",
      "\n",
      "Test set: Average loss: 0.0993, Accuracy: 9687/10000 (97%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.172540\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.051390\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.165514\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.029456\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.040389\n",
      "\n",
      "Test set: Average loss: 0.0789, Accuracy: 9754/10000 (98%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.087020\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.008725\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.120347\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.071900\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.059783\n",
      "\n",
      "Test set: Average loss: 0.0754, Accuracy: 9763/10000 (98%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.109540\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.087451\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.033035\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.087656\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.116632\n",
      "\n",
      "Test set: Average loss: 0.0717, Accuracy: 9769/10000 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#define model and optimizer\n",
    "model = Net()\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=1)\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=0.7)\n",
    "\n",
    "#train CNN model for five epochs\n",
    "for epoch in range(5):\n",
    "    train(model, train_loader, optimizer, epoch)\n",
    "    test(model, test_loader)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a MIP Formulation for the Trained Convolutional Neural Network\n",
    "\n",
    "We are now ready to use OMLT to formulate the trained model within a Pyomo optimization model. The nonsmooth ReLU activation function requires using a full-space representation, which uses the `NeuralNetworkFormulation` object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define a neural network without the final `LogSoftmax` activation. Although this activation helps greatly in training the neural network model, it is not trivial to encode in the optimization model. The ranking of the output labels remains the same without the activation, so it can be omitted when finding optimal adversaries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NoSoftmaxNet(nn.Module):\n",
    "    #define layers of neural network\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1  = nn.Conv2d(1, 4, (4,4), (2,2), 0)\n",
    "        self.conv2  = nn.Conv2d(4, 4, (4,4), (2,2), 0)\n",
    "        self.hidden1 = nn.Linear(5 * 5 * 4, hidden_size)\n",
    "        self.output  = nn.Linear(hidden_size, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    #define forward pass of neural network\n",
    "    def forward(self, x):\n",
    "        self.x1 = self.conv1(x)\n",
    "        self.x2 = self.relu(self.x1)\n",
    "        self.x3 = self.conv2(self.x2)\n",
    "        self.x4 = self.relu(self.x3)\n",
    "        self.x5 = self.hidden1(self.x4.view((-1,5*5*4)))\n",
    "        self.x6 = self.relu(self.x5)\n",
    "        x = self.output(self.x6)    \n",
    "        return x\n",
    "\n",
    "#create neural network without LogSoftmax and load parameters from existing model\n",
    "model2 = NoSoftmaxNet()\n",
    "model2.load_state_dict(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define an instance of the optimal adversary problem. We formulate the optimization problem as: <br>\n",
    "\n",
    "$\n",
    "\\begin{align*} \n",
    "& \\max_x \\ y_k - y_j \\\\\n",
    "& s.t. y_k = N_k(x) \\\\ \n",
    "&\\quad |x - \\bar{x}|_\\infty \\leq 0.05\n",
    "\\end{align*}\n",
    "$\n",
    "\n",
    "where $\\bar{x}$ corresponds to an image in the test dataset with true label `j`, and $N_k(x)$ is the value of the CNN output corresponding to adversarial label `k` given input `x`. PyTorch needs to trace the model execution to export it to ONNX, so we also define a dummy input tensor `x_temp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load image and true label from test set with index 'problem_index'\n",
    "problem_index = 0\n",
    "image = dataset2[problem_index][0].detach().numpy()\n",
    "label = dataset2[problem_index][1]\n",
    "\n",
    "#define input region defined by infinity norm\n",
    "epsilon_infty = 1e-3\n",
    "lb = np.maximum(0, image - epsilon_infty)\n",
    "ub = np.minimum(1, image + epsilon_infty)\n",
    "\n",
    "#save input bounds as dictionary, note that the first index 0 corresponds to the single-channel input\n",
    "input_bounds = {}\n",
    "for i in range(28):\n",
    "    for j in range(28):\n",
    "        input_bounds[(0,i,j)] = (float(lb[0][i,j]), float(ub[0][i,j])) \n",
    "    \n",
    "#define dummy input tensor    \n",
    "x = dataset2[problem_index][0].view(-1,1,28,28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now export the PyTorch model as an ONNX model and use `load_onnx_neural_network_with_bounds` to load it into OMLT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tempfile.NamedTemporaryFile(suffix='.onnx', delete=False) as f:\n",
    "    #export neural network to ONNX\n",
    "    torch.onnx.export(\n",
    "        model2,\n",
    "        x,\n",
    "        f,\n",
    "        input_names=['input'],\n",
    "        output_names=['output'],\n",
    "        dynamic_axes={\n",
    "            'input': {0: 'batch_size'},\n",
    "            'output': {0: 'batch_size'}\n",
    "        }\n",
    "    )\n",
    "    #write ONNX model and its bounds using OMLT\n",
    "    write_onnx_model_with_bounds(f.name, None, input_bounds)\n",
    "    #load the network definition from the ONNX model\n",
    "    network_definition = load_onnx_neural_network_with_bounds(f.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a sanity check before creating the optimization model, we can print the properties of the neural network layers from `network_definition`. This allows us to check input/output sizes, as well as activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tInputLayer(input_size=[1, 28, 28], output_size=[1, 28, 28])\tlinear\n",
      "1\tConvLayer(input_size=[1, 28, 28], output_size=[4, 13, 13], strides=[2, 2], kernel_shape=(4, 4))\trelu\n",
      "2\tConvLayer(input_size=[4, 13, 13], output_size=[4, 5, 5], strides=[2, 2], kernel_shape=(4, 4))\trelu\n",
      "3\tDenseLayer(input_size=[1, 100], output_size=[1, 50])\trelu\n",
      "4\tDenseLayer(input_size=[1, 50], output_size=[1, 10])\tlinear\n"
     ]
    }
   ],
   "source": [
    "for layer_id, layer in enumerate(network_definition.layers):\n",
    "    print(f\"{layer_id}\\t{layer}\\t{layer.activation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can load `network_definition` as a full-space `FullSpaceNNFormulation` object.OMLT doesn't include a formulation for sigmoid, so define it here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "formulation = FullSpaceNNFormulation(network_definition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solve Optimal Adversary Problem in Pyomo\n",
    "\n",
    "We now encode the trained neural network in a Pyomo model from the `FullSpaceNNFormulation` object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create pyomo model\n",
    "m = pyo.ConcreteModel()\n",
    "\n",
    "#create an OMLT block for the neural network and build its formulation\n",
    "m.nn = OmltBlock()\n",
    "m.nn.build_formulation(formulation) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define an adversarial label as the true label plus one (or zero if the true label is nine), as well as the objective function for optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversary = (label + 1) % 10\n",
    "m.obj = pyo.Objective(expr=(-(m.nn.outputs[0,adversary]-m.nn.outputs[0,label])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we solve the optimal adversary problem using a mixed-integer solver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the CBC MILP Solver \n",
      "Version: 2.10.5 \n",
      "Build Date: Oct 15 2020 \n",
      "\n",
      "command line - /home/jhjalvi/anaconda3/envs/tensorflow/bin/cbc -printingOptions all -import /tmp/tmpng1dkne8.pyomo.lp -stat=1 -solve -solu /tmp/tmpng1dkne8.pyomo.soln (default strategy 1)\n",
      "Option for printingOptions changed from normal to all\n",
      "Presolve 2699 (-3040) rows, 2763 (-2108) columns and 25487 (-7760) elements\n",
      "Statistics for presolved model\n",
      "Original problem has 826 integers (826 of which binary)\n",
      "Presolved problem has 481 integers (481 of which binary)\n",
      "==== 2712 zero objective 52 different\n",
      "==== absolute objective values 52 different\n",
      "==== for integers 481 zero objective 1 different\n",
      "481 variables have objective of 0\n",
      "==== for integers absolute objective values 1 different\n",
      "481 variables have objective of 0\n",
      "===== end objective counts\n",
      "\n",
      "\n",
      "Problem has 2699 rows, 2763 columns (51 with objective) and 25487 elements\n",
      "There are 1 singletons with objective \n",
      "Column breakdown:\n",
      "0 of type 0.0->inf, 1539 of type 0.0->up, 0 of type lo->inf, \n",
      "743 of type lo->up, 0 of type free, 0 of type fixed, \n",
      "0 of type -inf->0.0, 0 of type -inf->up, 481 of type 0.0->1.0 \n",
      "Row breakdown:\n",
      "687 of type E 0.0, 0 of type E 1.0, 0 of type E -1.0, \n",
      "50 of type E other, 0 of type G 0.0, 0 of type G 1.0, \n",
      "0 of type G other, 1481 of type L 0.0, 0 of type L 1.0, \n",
      "481 of type L other, 0 of type Range 0.0->1.0, 0 of type Range other, \n",
      "0 of type Free \n",
      "Continuous objective value is -37.9372 - 0.06 seconds\n",
      "Cgl0003I 37 fixed, 0 tightened bounds, 2 strengthened rows, 0 substitutions\n",
      "Cgl0003I 0 fixed, 0 tightened bounds, 2 strengthened rows, 0 substitutions\n",
      "Cgl0004I processed model has 1898 rows, 1957 columns (341 integer (341 of which binary)) and 30889 elements\n",
      "Cbc0038I Initial state - 260 integers unsatisfied sum - 72.2317\n",
      "Cbc0038I Pass   1: suminf.    0.00000 (0) obj. 14.4369 iterations 1070\n",
      "Cbc0038I Solution found of 14.4369\n",
      "Cbc0038I Relaxing continuous gives 14.4108\n",
      "Cbc0038I Before mini branch and bound, 81 integers at bound fixed and 545 continuous\n",
      "Cbc0038I Full problem 1898 rows 1957 columns, reduced to 1449 rows 1199 columns - 43 fixed gives 1395, 1148 - still too large\n",
      "Cbc0038I Full problem 1898 rows 1957 columns, reduced to 1360 rows 1116 columns - too large\n",
      "Cbc0038I Mini branch and bound did not improve solution (0.57 seconds)\n",
      "Cbc0038I Freeing continuous variables gives a solution of 14.4108\n",
      "Cbc0038I Round again with cutoff of 14.3956\n",
      "Cbc0038I Pass   2: suminf.    0.03374 (7) obj. 14.3956 iterations 279\n",
      "Cbc0038I Pass   3: suminf.    0.00000 (0) obj. 14.3956 iterations 296\n",
      "Cbc0038I Solution found of 14.3956\n",
      "Cbc0038I Relaxing continuous gives 14.3885\n",
      "Cbc0038I Before mini branch and bound, 81 integers at bound fixed and 602 continuous\n",
      "Cbc0038I Full problem 1898 rows 1957 columns, reduced to 1378 rows 1103 columns - 154 fixed gives 1178, 901 - still too large\n",
      "Cbc0038I Full problem 1898 rows 1957 columns, reduced to 1141 rows 870 columns - too large\n",
      "Cbc0038I Mini branch and bound did not improve solution (0.91 seconds)\n",
      "Cbc0038I Round again with cutoff of 14.3626\n",
      "Cbc0038I Pass   4: suminf.    0.29743 (7) obj. 14.3626 iterations 0\n",
      "Cbc0038I Pass   5: suminf.    0.32948 (5) obj. 14.3626 iterations 686\n",
      "Cbc0038I Pass   6: suminf.    0.14155 (4) obj. 14.3626 iterations 573\n",
      "Cbc0038I Pass   7: suminf.    0.29982 (1) obj. 14.3626 iterations 374\n",
      "Cbc0038I Pass   8: suminf.    0.50639 (5) obj. 14.3626 iterations 1275\n",
      "Cbc0038I Pass   9: suminf.    0.28695 (8) obj. 14.3626 iterations 634\n",
      "Cbc0038I Pass  10: suminf.    0.41355 (2) obj. 14.3626 iterations 322\n",
      "Cbc0038I Pass  11: suminf.    0.27428 (2) obj. 14.3626 iterations 317\n",
      "Cbc0038I Pass  12: suminf.    0.45796 (28) obj. 14.3626 iterations 1231\n",
      "Cbc0038I Pass  13: suminf.    0.49280 (11) obj. 14.3626 iterations 560\n",
      "Cbc0038I Pass  14: suminf.    0.30608 (16) obj. 14.3626 iterations 565\n",
      "Cbc0038I Pass  15: suminf.    0.43719 (20) obj. 14.3626 iterations 365\n",
      "Cbc0038I Pass  16: suminf.    0.49693 (50) obj. 14.3626 iterations 2015\n",
      "Cbc0038I Pass  17: suminf.    0.48582 (39) obj. 14.3626 iterations 232\n",
      "Cbc0038I Pass  18: suminf.    0.44120 (32) obj. 14.3626 iterations 816\n",
      "Cbc0038I Pass  19: suminf.    0.24483 (6) obj. 14.3626 iterations 635\n",
      "Cbc0038I Pass  20: suminf.    0.35867 (4) obj. 14.3626 iterations 549\n",
      "Cbc0038I Pass  21: suminf.    0.21177 (13) obj. 14.3626 iterations 511\n",
      "Cbc0038I Pass  22: suminf.    0.59514 (35) obj. 14.3626 iterations 1757\n",
      "Cbc0038I Pass  23: suminf.    0.43224 (16) obj. 14.3626 iterations 1062\n",
      "Cbc0038I Pass  24: suminf.    0.31914 (15) obj. 14.3626 iterations 339\n",
      "Cbc0038I Pass  25: suminf.    0.42907 (8) obj. 14.3626 iterations 1130\n",
      "Cbc0038I Pass  26: suminf.    0.49623 (4) obj. 14.3626 iterations 306\n",
      "Cbc0038I Pass  27: suminf.    0.41943 (5) obj. 14.3626 iterations 190\n",
      "Cbc0038I Pass  28: suminf.    0.49367 (3) obj. 14.3626 iterations 224\n",
      "Cbc0038I Pass  29: suminf.    0.66800 (35) obj. 14.3626 iterations 1959\n",
      "Cbc0038I Pass  30: suminf.    0.66600 (48) obj. 14.3626 iterations 259\n",
      "Cbc0038I Pass  31: suminf.    0.41020 (10) obj. 14.3626 iterations 920\n",
      "Cbc0038I Pass  32: suminf.    0.29047 (2) obj. 14.3626 iterations 343\n",
      "Cbc0038I Rounding solution of 14.3802 is better than previous of 14.3885\n",
      "\n",
      "Cbc0038I After 3.23 seconds - Feasibility pump exiting with objective of 14.3802 - took 2.76 seconds\n",
      "Cbc0012I Integer solution of 14.379118 found by feasibility pump after 0 iterations and 0 nodes (3.64 seconds)\n",
      "Cbc0038I Full problem 1898 rows 1957 columns, reduced to 1703 rows 1780 columns - 154 fixed gives 1549, 1626 - still too large\n",
      "Cbc0031I 304 added rows had average density of 21.703947\n",
      "Cbc0013I At root node, 304 cuts changed objective from 14.25901 to 14.285459 in 10 passes\n",
      "Cbc0014I Cut generator 0 (Probing) - 1158 row cuts average 2.2 elements, 0 column cuts (196 active)  in 0.056 seconds - new frequency is 1\n",
      "Cbc0014I Cut generator 1 (Gomory) - 577 row cuts average 38.6 elements, 0 column cuts (0 active)  in 0.099 seconds - new frequency is 1\n",
      "Cbc0014I Cut generator 2 (Knapsack) - 0 row cuts average 0.0 elements, 0 column cuts (0 active)  in 0.030 seconds - new frequency is -100\n",
      "Cbc0014I Cut generator 3 (Clique) - 0 row cuts average 0.0 elements, 0 column cuts (0 active)  in 0.001 seconds - new frequency is -100\n",
      "Cbc0014I Cut generator 4 (MixedIntegerRounding2) - 510 row cuts average 13.4 elements, 0 column cuts (0 active)  in 0.035 seconds - new frequency is 1\n",
      "Cbc0014I Cut generator 5 (FlowCover) - 3 row cuts average 2.7 elements, 0 column cuts (0 active)  in 0.053 seconds - new frequency is -100\n",
      "Cbc0014I Cut generator 6 (TwoMirCuts) - 573 row cuts average 44.9 elements, 0 column cuts (0 active)  in 0.079 seconds - new frequency is -100\n",
      "Cbc0010I After 0 nodes, 1 on tree, 14.379118 best solution, best possible 14.285459 (5.37 seconds)\n",
      "Cbc0038I Full problem 1898 rows 1957 columns, reduced to 1532 rows 1612 columns - 46 fixed gives 1486, 1566 - still too large\n",
      "Cbc0012I Integer solution of 14.33724 found by rounding after 7088 iterations and 56 nodes (10.97 seconds)\n",
      "Cbc0012I Integer solution of 14.337215 found by rounding after 7160 iterations and 60 nodes (11.59 seconds)\n",
      "Cbc0012I Integer solution of 14.337045 found by rounding after 7194 iterations and 73 nodes (12.28 seconds)\n",
      "Cbc0038I Full problem 1898 rows 1957 columns, reduced to 1367 rows 1448 columns - 10 fixed gives 1357, 1438 - still too large\n",
      "Cbc0038I Full problem 1898 rows 1957 columns, reduced to 1303 rows 1363 columns - too large\n",
      "Cbc0010I After 100 nodes, 35 on tree, 14.337045 best solution, best possible 14.285459 (13.25 seconds)\n",
      "Cbc0012I Integer solution of 14.337023 found by rounding after 7677 iterations and 101 nodes (13.80 seconds)\n",
      "Cbc0012I Integer solution of 14.336949 found by rounding after 8096 iterations and 113 nodes (14.48 seconds)\n",
      "Cbc0012I Integer solution of 14.336743 found by rounding after 9355 iterations and 151 nodes (15.49 seconds)\n",
      "Cbc0012I Integer solution of 14.336346 found by rounding after 10961 iterations and 195 nodes (16.71 seconds)\n",
      "Cbc0038I Full problem 1898 rows 1957 columns, reduced to 1411 rows 1492 columns - 17 fixed gives 1394, 1475 - still too large\n",
      "Cbc0038I Full problem 1898 rows 1957 columns, reduced to 1342 rows 1402 columns - too large\n",
      "Cbc0010I After 200 nodes, 11 on tree, 14.336346 best solution, best possible 14.285459 (17.20 seconds)\n",
      "Cbc0012I Integer solution of 14.336307 found by rounding after 17193 iterations and 269 nodes (22.12 seconds)\n",
      "Cbc0038I Full problem 1898 rows 1957 columns, reduced to 1222 rows 1035 columns - 14 fixed gives 1190, 1002 - still too large\n",
      "Cbc0010I After 300 nodes, 16 on tree, 14.336307 best solution, best possible 14.285459 (24.93 seconds)\n",
      "Cbc0012I Integer solution of 14.336183 found by rounding after 19469 iterations and 317 nodes (25.57 seconds)\n",
      "Cbc0012I Integer solution of 14.336167 found by rounding after 20905 iterations and 350 nodes (26.83 seconds)\n",
      "Cbc0012I Integer solution of 14.336148 found by rounding after 21086 iterations and 356 nodes (27.36 seconds)\n",
      "Cbc0004I Integer solution of 14.336118 found after 21577 iterations and 396 nodes (29.23 seconds)\n",
      "Cbc0010I After 400 nodes, 5 on tree, 14.336118 best solution, best possible 14.285459 (29.25 seconds)\n",
      "Cbc0012I Integer solution of 14.336084 found by rounding after 22464 iterations and 423 nodes (30.73 seconds)\n",
      "Cbc0004I Integer solution of 14.336034 found after 23261 iterations and 466 nodes (32.20 seconds)\n",
      "Cbc0038I Full problem 1898 rows 1957 columns, reduced to 1186 rows 1009 columns - 2 fixed gives 1184, 1007 - still too large\n",
      "Cbc0038I Full problem 1898 rows 1957 columns, reduced to 1162 rows 986 columns - too large\n",
      "Cbc0010I After 500 nodes, 17 on tree, 14.336034 best solution, best possible 14.285459 (33.07 seconds)\n",
      "Cbc0012I Integer solution of 14.336006 found by rounding after 25571 iterations and 506 nodes (33.50 seconds)\n",
      "Cbc0004I Integer solution of 14.335911 found after 26017 iterations and 533 nodes (34.13 seconds)\n",
      "Cbc0038I Full problem 1898 rows 1957 columns, reduced to 1182 rows 1006 columns - 3 fixed gives 1178, 1002 - still too large\n",
      "Cbc0038I Full problem 1898 rows 1957 columns, reduced to 1158 rows 983 columns - too large\n",
      "Cbc0010I After 600 nodes, 26 on tree, 14.335911 best solution, best possible 14.285459 (39.42 seconds)\n",
      "Cbc0012I Integer solution of 14.335697 found by rounding after 28755 iterations and 609 nodes (39.84 seconds)\n",
      "Cbc0004I Integer solution of 14.335546 found after 28897 iterations and 644 nodes (40.56 seconds)\n",
      "Cbc0001I Search completed - best objective 14.33554625313286, took 31212 iterations and 655 nodes (42.44 seconds)\n",
      "Cbc0032I Strong branching done 3062 times (39800 iterations), fathomed 12 nodes and fixed 293 variables\n",
      "Cbc0035I Maximum depth 45, 61 variables fixed on reduced cost\n",
      "Cuts at root node changed objective from 14.259 to 14.2855\n",
      "Probing was tried 158 times and created 1751 cuts of which 196 were active after adding rounds of cuts (0.232 seconds)\n",
      "Gomory was tried 158 times and created 1239 cuts of which 0 were active after adding rounds of cuts (0.327 seconds)\n",
      "Knapsack was tried 10 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.030 seconds)\n",
      "Clique was tried 10 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.001 seconds)\n",
      "MixedIntegerRounding2 was tried 158 times and created 1282 cuts of which 0 were active after adding rounds of cuts (0.335 seconds)\n",
      "FlowCover was tried 10 times and created 3 cuts of which 0 were active after adding rounds of cuts (0.053 seconds)\n",
      "TwoMirCuts was tried 10 times and created 573 cuts of which 0 were active after adding rounds of cuts (0.079 seconds)\n",
      "ZeroHalf was tried 1 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "\n",
      "Result - Optimal solution found\n",
      "\n",
      "Objective value:                14.33554625\n",
      "Enumerated nodes:               655\n",
      "Total iterations:               31212\n",
      "Time (CPU seconds):             43.57\n",
      "Time (Wallclock seconds):       48.74\n",
      "\n",
      "Total time (CPU seconds):       43.61   (Wallclock seconds):       48.79\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Problem': [{'Name': 'unknown', 'Lower bound': 14.33554625, 'Upper bound': 14.33554625, 'Number of objectives': 1, 'Number of constraints': 2699, 'Number of variables': 2763, 'Number of binary variables': 826, 'Number of integer variables': 826, 'Number of nonzeros': 51, 'Sense': 'minimize'}], 'Solver': [{'Status': 'ok', 'User time': -1.0, 'System time': 43.61, 'Wallclock time': 48.79, 'Termination condition': 'optimal', 'Termination message': 'Model was solved to optimality (subject to tolerances), and an optimal solution is available.', 'Statistics': {'Branch and bound': {'Number of bounded subproblems': 655, 'Number of created subproblems': 655}, 'Black box': {'Number of iterations': 31212}}, 'Error rc': 0, 'Time': 48.81346607208252}], 'Solution': [OrderedDict([('number of solutions', 0), ('number of solutions displayed', 0)])]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solver = pyo.SolverFactory('cbc')\n",
    "solver.solve(m, tee=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b8f31a8284ce774e9ad8d309790c576c984c0620550967f9ef361ac8e66f487d"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
